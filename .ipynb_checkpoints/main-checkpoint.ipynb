{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d5f120-4f0c-467f-8d17-c2e1fc8b0b80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17675/2163532279.py:25: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(param)\n",
      "/tmp/ipykernel_17675/2163532279.py:27: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  init.uniform(param)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import sys\n",
    "from ImportantConfig import Config\n",
    "config = Config()\n",
    "from sql2fea import TreeBuilder,value_extractor\n",
    "from NET import TreeNet\n",
    "from sql2fea import Sql2Vec\n",
    "from TreeLSTM import SPINN\n",
    "\n",
    "sys.path.append('/home/ubuntu/project/HyperQO')\n",
    "\n",
    "sys.stdout = open(config.log_file, \"w\")\n",
    "random.seed(113)\n",
    "with open(config.queries_file) as f:\n",
    "    import json\n",
    "    queries = json.load(f)\n",
    "\n",
    "tree_builder = TreeBuilder()\n",
    "sql2vec = Sql2Vec()\n",
    "value_network = SPINN(head_num=config.head_num, input_size=37, hidden_size=config.hidden_size, table_num = 50,sql_size = 1).to(config.device)\n",
    "for name, param in value_network.named_parameters():\n",
    "    from torch.nn import init\n",
    "    if len(param.shape)==2:\n",
    "        init.xavier_normal(param)\n",
    "    else:\n",
    "        init.uniform(param)\n",
    "\n",
    "\n",
    "treenet_model = TreeNet(tree_builder, value_network)\n",
    "\n",
    "mask = (torch.rand(1,config.head_num,device = config.device)<0.9).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beaf5e3-948f-4582-b908-bba501349921",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train_dataloader\n",
    ":sql,plan_json,target_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ccc193-6ee8-4fe5-87af-60e753bd20e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query</th>\n",
       "      <th>cost_no_index</th>\n",
       "      <th>cost_dta</th>\n",
       "      <th>cost_reduction</th>\n",
       "      <th>cost_reduction_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>select  i_item_id, \\n        avg(ss_quantity) ...</td>\n",
       "      <td>108534.81</td>\n",
       "      <td>69925.31</td>\n",
       "      <td>38609.50</td>\n",
       "      <td>0.355734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>select sum (ss_quantity)\\n from store_sales, s...</td>\n",
       "      <td>147137.68</td>\n",
       "      <td>86652.87</td>\n",
       "      <td>60484.81</td>\n",
       "      <td>0.411076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>select  i_item_id\\n       ,i_item_desc \\n     ...</td>\n",
       "      <td>50155.33</td>\n",
       "      <td>3944.83</td>\n",
       "      <td>46210.50</td>\n",
       "      <td>0.921348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>with ss_items as\\n (select i_item_id item_id\\n...</td>\n",
       "      <td>162566.89</td>\n",
       "      <td>839.12</td>\n",
       "      <td>161727.77</td>\n",
       "      <td>0.994838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>select  asceding.rnk, i1.i_product_name best_p...</td>\n",
       "      <td>274060.77</td>\n",
       "      <td>48.66</td>\n",
       "      <td>274012.11</td>\n",
       "      <td>0.999822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              query  \\\n",
       "0           0  select  i_item_id, \\n        avg(ss_quantity) ...   \n",
       "1           1  select sum (ss_quantity)\\n from store_sales, s...   \n",
       "2           2  select  i_item_id\\n       ,i_item_desc \\n     ...   \n",
       "3           3  with ss_items as\\n (select i_item_id item_id\\n...   \n",
       "4           4  select  asceding.rnk, i1.i_product_name best_p...   \n",
       "\n",
       "   cost_no_index  cost_dta  cost_reduction  cost_reduction_ratio  \n",
       "0      108534.81  69925.31        38609.50              0.355734  \n",
       "1      147137.68  86652.87        60484.81              0.411076  \n",
       "2       50155.33   3944.83        46210.50              0.921348  \n",
       "3      162566.89    839.12       161727.77              0.994838  \n",
       "4      274060.77     48.66       274012.11              0.999822  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('./information/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bc04d97-6c51-43fa-9e02-f14adef0cac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x=train['query'].values\n",
    "y=train['cost_reduction_ratio'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9abcdb-4c47-4eec-b342-95103f100bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train['query'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c7b661-b801-466d-9dc9-1a72a7b97db1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PGUtils import pgrunner\n",
    "plan_json_PG_list=[]\n",
    "for sql in train['query'].values:\n",
    "    plan_json_PG_list.append(pgrunner.getCostPlanJson(sql))\n",
    "# plan_json_PG_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9534eb8-8b01-4980-8c5a-16f49692b8bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader=list(zip(train['query'].values, plan_json_PG_list, train['cost_reduction_ratio'].values))\n",
    "# train_dataloader[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e5991-1d81-4105-a0d0-27ff8666b7da",
   "metadata": {},
   "source": [
    "###  训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8c5476-ac90-4eb5-a3d6-8d0df0dc4e06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0958139896392822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8610769510269165"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs=1\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for batch_data in train_dataloader[:1000]:\n",
    "        sql_vec,alias = sql2vec.to_vec(batch_data[0])\n",
    "        plan_json, target_value = batch_data[1], batch_data[2]\n",
    "        loss, mean, variance, exp_variance = treenet_model.train(plan_json, sql_vec, target_value, mask, is_train=True)\n",
    "        total_loss +=loss\n",
    "        display(loss)\n",
    "    # 打印或记录训练过程中的损失等信息\n",
    "    avg_loss = total_loss / 1000\n",
    "    display(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55033c6-b0ec-4b39-b820-f0948f0fb9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for test_batch_data in train_dataloader[-9:]:\n",
    "        sql_vec,alias = sql2vec.to_vec(test_batch_data[0])\n",
    "        plan_json, target_value = test_batch_data[1], test_batch_data[2]\n",
    "        _, mean, _, exp_variance = treenet_model.train(plan_json, sql_vec, target_value, mask, is_train=False)\n",
    "        display(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6aea18-c2ab-43db-ae81-7a9603e055c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[2] for x in train_dataloader[-9:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dda8140d-6dcd-4c62-b19b-77172843e23d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207c4bd2-c275-42d3-8a19-f4b9b5241612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/ubuntu/project/HyperQO/lightning_logs\n",
      "\n",
      "  | Name          | Type  | Params\n",
      "----------------------------------------\n",
      "0 | value_network | SPINN | 157 K \n",
      "----------------------------------------\n",
      "157 K     Trainable params\n",
      "0         Non-trainable params\n",
      "157 K     Total params\n",
      "0.630     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "\n",
    "\n",
    "\n",
    "# 定义 LightningModule 类\n",
    "class MyLightningModule(LightningModule):\n",
    "    def __init__(self, treenet_model, train_dataloader, mask):\n",
    "        super().__init__()\n",
    "        self.treenet_model = treenet_model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.value_network = treenet_model.value_network\n",
    "        self.mask = mask\n",
    "\n",
    "    def forward(self, batch_data):\n",
    "        sql_vec, alias = np.array([1]),set(['kt1'])\n",
    "        plan_json, target_value = batch_data[1], batch_data[2]\n",
    "        loss, mean, variance, exp_variance = self.treenet_model.train(plan_json, sql_vec, target_value, self.mask, is_train=False)\n",
    "        return mean\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, mean, variance, exp_variance = self.treenet_model.train(plan_json, sql_vec, target_value, self.mask, is_train=False)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.value_network.parameters(), lr=3e-4)\n",
    "\n",
    "# 创建 LightningModule 实例\n",
    "model = MyLightningModule(treenet_model, train_dataloader, mask)\n",
    "\n",
    "# 创建 Trainer 实例并训练模型\n",
    "trainer = Trainer(max_epochs=1)  \n",
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb2fb0-5d36-4bba-8ff7-52113fb1314d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32a264b5-4cf7-4dbb-b74f-7c9aafbeecbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 10, 5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2, 3, 8]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[9, 1, 7]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # 示例数据\n",
    "batch_size = 3  # 定义批次大小\n",
    "\n",
    "# 首先打乱列表顺序\n",
    "random.shuffle(data)\n",
    "\n",
    "# 然后按照固定大小划分批次\n",
    "num_batches = len(data) // batch_size\n",
    "batches = [data[i * batch_size: (i + 1) * batch_size] for i in range(num_batches)]\n",
    "\n",
    "# 输出随机划分的批次\n",
    "for batch in batches:\n",
    "    display(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36feb303-14f3-4ecb-a091-e6fdcd0048f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
